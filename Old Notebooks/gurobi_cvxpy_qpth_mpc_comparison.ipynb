{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/annechris13/Master-Thesis/blob/master/performance_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RW72Blyw1922"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "import random\n",
    "# import warnings\n",
    "# warnings.filterwarnings('error')\n",
    "import time\n",
    "import cvxpy as cp\n",
    "from scipy.linalg import sqrtm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VBiXLGmPd2K-",
    "outputId": "ba4eeec2-fd93-436c-cdd6-1bc52b1fb79b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "BGYHKVEEFIUm",
    "outputId": "9b9a8e07-af9e-47d8-80a2-2c81f8e6a53d"
   },
   "outputs": [],
   "source": [
    "# !pip install import-ipynb\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "QrZPjwoLFM9b",
    "outputId": "22b4f875-3750-4502-8e13-b95c004a5dc0"
   },
   "outputs": [],
   "source": [
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks\"\n",
    "import mpc_class\n",
    "import qpth_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize the mpc solver class \n",
    "mpc_solver=mpc_class.mpc(max_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AHE7paKteMaf",
    "outputId": "8f8fb60c-5084-423a-8751-932a5a6d2c53"
   },
   "outputs": [],
   "source": [
    "# %cd \"/content\"\n",
    "df=pd.read_csv('test_cases.csv')\n",
    "df=df.iloc[:1000]\n",
    "seeds=df[\"seed\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HUHVFOEUFke"
   },
   "source": [
    "# Test on individual problems - gurobi & cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZvzRLCwCPPz0"
   },
   "outputs": [],
   "source": [
    "def qp_cvxpy(n,P,q,G,h,A,b):\n",
    "    x= cp.Variable(n)\n",
    "    objective=cp.Minimize((1/2)*cp.sum_squares(P*x) + q.T @ x)\n",
    "    constraints=[G@x <=h,A@x ==b]\n",
    "    prob=cp.Problem(objective,constraints)\n",
    "    prob.solve(verbose=False)\n",
    "    cvxpy_optimum= prob.value\n",
    "    cvxpy_solution=x.value\n",
    "    return cvxpy_optimum,cvxpy_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qp_gurobi(n,m,p,P,q,G,h,A,b):\n",
    "    model = gp.Model(\"qp\")\n",
    "    model.setParam( 'OutputFlag', False )\n",
    "    x={}\n",
    "    for i in range(n):\n",
    "        x[i]=model.addVar(lb=-GRB.INFINITY,ub=GRB.INFINITY)\n",
    "    obj_0=0\n",
    "    obj_1=0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            obj_0+=P[i][j]*x[i]*x[j]\n",
    "        obj_1+=q[i]*x[i]\n",
    "    model.setObjective(0.5*obj_0+obj_1)\n",
    "    for i in range(m):\n",
    "        cons=0\n",
    "        for j in range(n):\n",
    "            cons+=G[i][j]*x[j]\n",
    "        model.addConstr(cons<=h[i])\n",
    "    for i in range(p):\n",
    "        cons=0\n",
    "        for j in range(n):\n",
    "            cons+=A[i][j]*x[j]\n",
    "        model.addConstr(cons==b[i])\n",
    "    model.optimize()\n",
    "    try:\n",
    "        gurobi_sol=[v.x for v in model.getVars()]\n",
    "        gurobi_opt=model.objVal\n",
    "    except:\n",
    "        gurobi_sol=None\n",
    "        gurobi_opt=None\n",
    "    return np.array(gurobi_opt),gurobi_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8CfqIJAvQkqG",
    "outputId": "2f63e787-b5ac-4217-d0f8-f0b9efc04c1b"
   },
   "outputs": [],
   "source": [
    "n=6\n",
    "m=6\n",
    "p=3\n",
    "nbatch=1\n",
    "import random as r\n",
    "gurobi_time=0.0\n",
    "gurobi_errors=[]\n",
    "ge=0\n",
    "cvxpy_time=0.0\n",
    "cvxpy_errors=[]\n",
    "cvxpy_opt=[]\n",
    "ce=0\n",
    "gurobi_opt=[]\n",
    "# columns=[\"seed\"]+[str(i)+\"cp\" for i in range(n)]\n",
    "results=pd.DataFrame([])#,columns=columns)\n",
    "for k,s in enumerate(seeds):\n",
    "    r.seed(s)\n",
    "    P=make_spd_matrix(n, random_state=s)\n",
    "    q=np.array([r.random()*10 for i in range(n)]).reshape(n).astype(float)\n",
    "    G=np.array([r.random()*10*((-1)**r.randint(0,1)) for i in range(m*n)]).reshape(m,n).astype(float)\n",
    "    h=np.array([0 for i in range(m)]).reshape(n).astype(float)\n",
    "    A=np.array([r.random()*10 for i in range(p*n)]).reshape(p,n).astype(float)\n",
    "    b=np.array([r.random()*10 for i in range(p)]).reshape(p).astype(float)\n",
    "#     q=np.array([r.randint(0,9) for i in range(n)]).reshape(n).astype(float)\n",
    "#     G=np.array([r.randint(0,9)*((-1)**r.randint(0,1)) for i in range(m*n)]).reshape(m,n).astype(float)\n",
    "#     h=np.array([0 for i in range(m)]).reshape(n).astype(float)\n",
    "#     A=np.array([r.randint(0,9) for i in range(p*n)]).reshape(p,n).astype(float)\n",
    "#     b=np.array([r.randint(0,9) for i in range(p)]).reshape(p).astype(float)\n",
    "    #get gurobi solution\n",
    "    start_gur=time.time()\n",
    "    y,x=qp_gurobi(n,m,p,P,q,G,h,A,b)\n",
    "#     print(np.round(x,4))\n",
    "#     print(np.round(y,4))\n",
    "    \n",
    "    \n",
    "#     model = gp.Model(\"matrix1\")\n",
    "#     model.setParam( 'OutputFlag', False )\n",
    "#     x = model.addMVar(shape=n, name=\"x\",lb=-GRB.INFINITY,ub=GRB.INFINITY)\n",
    "#     model.addConstr(G @ x <= h, name=\"ineq\")\n",
    "#     model.addConstr(A @ x == b, name=\"eq\")\n",
    "#     model.setMObjective(0.5*P,q.T,0.0,x,x,x, GRB.MINIMIZE)\n",
    "#     # Optimize model\n",
    "#     model.optimize()\n",
    "    gurobi_time+=time.time()-start_gur\n",
    "    re=pd.Series({\"seed\":s})\n",
    "    if x is not None:\n",
    "#         for v in model.getVars():\n",
    "        for i in range(n):\n",
    "            re=re.append(pd.Series({str(i)+\"gur\":np.round(x[i],4)}))\n",
    "            # print('%s %g' % (v.varName, v.x))\n",
    "        gurobi_opt.append(y)\n",
    "    else:\n",
    "        ge+=1\n",
    "        gurobi_errors.append(s)\n",
    "        for i in range(n):\n",
    "            re=re.append(pd.Series({str(i)+\"gur\":np.nan}))\n",
    "        gurobi_opt.append(0)\n",
    "    \n",
    "#     #get cvxpy solution\n",
    "    P = sqrtm(P)\n",
    "    start=time.time()\n",
    "    try:\n",
    "        x,y=qp_cvxpy(n,P,q,G,h,A,b)\n",
    "        cvxpy_time+=time.time()-start\n",
    "        cvxpy_opt.append(x)\n",
    "        for i in range(n):\n",
    "            if y is not None:\n",
    "                re=re.append(pd.Series({str(i)+\"cp\":np.round(y[i],4)}))\n",
    "\n",
    "            else:\n",
    "                cvxpy_errors.append(s)\n",
    "                re=re.append(pd.Series({str(i)+\"cp\":0}))\n",
    "    except:\n",
    "        cvxpy_opt.append(0)\n",
    "        cvxpy_errors.append(s)\n",
    "        re=re.append(pd.Series({str(i)+\"cp\":0}))\n",
    "    \n",
    "    \n",
    "    results=results.append(re,ignore_index=True )\n",
    "# cvxpy_errors=np.unique(cvxpy_errors)\n",
    "# ce=len(cvxpy_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qpHc3XPxUVQ5",
    "outputId": "ca8c3dd5-0205-41e3-ae3a-b7a1023cf40d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurobi time:  6.41616678237915\n"
     ]
    }
   ],
   "source": [
    "print(\"gurobi time: \", gurobi_time)\n",
    "# print(\"cvxpy time: \", cvxpy_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7EZGB5gUNYx"
   },
   "source": [
    "# Test on Batch of problems - qpth & mpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qEFx-wqoVvtP"
   },
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lk8sm1r0dWD4"
   },
   "outputs": [],
   "source": [
    "ip=\"csv\"\n",
    "df=df.iloc[:,:8]\n",
    "nbatch=len(df)\n",
    "nx=6\n",
    "nineq=6\n",
    "neq=3\n",
    "Q=[]\n",
    "p=[]\n",
    "G=[]\n",
    "h=[]\n",
    "A=[]\n",
    "b=[]\n",
    "for i in range(nbatch):\n",
    "  #generate random problems using seeds in the csv file\n",
    "  seed=int(df[\"seed\"][i])\n",
    "  random.seed(seed)\n",
    "  Q.append(make_spd_matrix(nx,random_state=seed).reshape(1,-1))\n",
    "#   p.append([random.randint(0,9) for i in range(nx)])#.astype(float))\n",
    "#   G.append([random.randint(0,9)*((-1)**random.randint(0,1)) for i in range(nineq*nx)])#.astype(float))\n",
    "#   h.append([0 for i in range(nineq)])#.astype(float))\n",
    "#   A.append([random.randint(0,9) for i in range(neq*nx)])#.astype(float))\n",
    "#   b.append([random.randint(0,9) for i in range(neq)])#.astype(float)  )\n",
    "\n",
    "  p.append([random.random()*10 for i in range(nx)])#.astype(float))\n",
    "  G.append([random.random()*10*((-1)**random.randint(0,1)) for i in range(nineq*nx)])#.astype(float))\n",
    "  h.append([0 for i in range(nineq)])#.astype(float))\n",
    "  A.append([random.random()*10 for i in range(neq*nx)])#.astype(float))\n",
    "  b.append([random.random()*10 for i in range(neq)])#.astype(float)  )\n",
    "\n",
    "Q=torch.tensor(Q).view(nbatch,nx,nx).type(torch.DoubleTensor)\n",
    "p=torch.tensor(p).view(nbatch,nx).type(torch.DoubleTensor)\n",
    "G=torch.tensor(G).view(nbatch,nineq,nx).type(torch.DoubleTensor)\n",
    "h=torch.tensor(h).view(nbatch,nineq).type(torch.DoubleTensor)\n",
    "A=torch.tensor(A).view(nbatch,neq,nx).type(torch.DoubleTensor)\n",
    "b=torch.tensor(b).view(nbatch,neq).type(torch.DoubleTensor)\n",
    "\n",
    "Q_batched=Q\n",
    "p_batched=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of mu not converged:  360\n",
      "mpc warning: Residuals not converged, need more itrations\n"
     ]
    }
   ],
   "source": [
    "#solve using mpc solver\n",
    "start=time.time()\n",
    "x_mpc,_=mpc_solver.solve(Q,p,G,h,A,b)\n",
    "mpc_time=time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "LAKY2we9VuRZ",
    "outputId": "130efc88-b503-43c7-be7f-e38388d3a8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qpth warning: Returning an inaccurate and potentially incorrect solution.\n",
      "mpc time:  0.5602896213531494\n",
      "qpth time:  4.894780874252319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#solve using qpt solver\n",
    "start=time.time()\n",
    "x_qpt,_,_,_=qpth_class.qpth_opt(Q,p,G,h,A,b)\n",
    "qpth_time=time.time()-start\n",
    "#print run times\n",
    "print(\"mpc time: \", mpc_time)\n",
    "print(\"qpth time: \", qpth_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "EjY2mKZ8XrYU",
    "outputId": "5588075c-5472-4522-ce6e-ae143c12937f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON AGAINST GUROBI:\n",
      "No.of problems solved:  642\n",
      "642\n",
      "\n",
      "No.of errors from cvxpy:  3  ( 0.47 %)\n",
      "No.of errors from MPC  22  ( 3.43 %)\n",
      "No.of errors from qpth  20  ( 3.12 %)\n",
      "______________________________________________\n",
      "\n",
      "\n",
      "COMPARISON AGAINST CVXPY:\n",
      "No.of problems solved:  1000\n",
      "641\n",
      "No.of errors from MPC:  19  ( 2.96 %)\n",
      "No.of errors from qpth:  17  ( 2.65 %)\n",
      "______________________________________________\n",
      "\n",
      "\n",
      "TIME COMPARISON:\n",
      "gurobi time:  6.41616678237915\n",
      "cvxpy time:  14.187674522399902\n",
      "mpc time:  0.5602896213531494\n",
      "qpth time:  4.894780874252319\n"
     ]
    }
   ],
   "source": [
    "cols_mpc=[str(i)+\"mpc\" for i in range(nx)]\n",
    "cols_qpt=[str(i)+\"qpt\" for i in range(nx)]\n",
    "cols_cp=[str(i)+\"cp\" for i in range(nx)]\n",
    "cols_gur=[str(i)+\"gur\" for i in range(nx)]\n",
    "error_qpt_cp=np.zeros(nbatch)\n",
    "error_mpc_cp=np.zeros(nbatch)\n",
    "error_qpt_gur=np.zeros(nbatch)\n",
    "error_mpc_gur=np.zeros(nbatch)\n",
    "error_cp_gur=np.zeros(nbatch)\n",
    "#results of mpc and qpt as data frames\n",
    "new_mpc=pd.DataFrame(x_mpc.numpy().round(4).reshape(nbatch,-1),columns=cols_mpc)\n",
    "new_qpt=pd.DataFrame(x_qpt.numpy().round(4).reshape(nbatch,-1),columns=cols_qpt)\n",
    "#results of cvxpy & gurobi\n",
    "tmp=results.copy()\n",
    "for i in range(nx):\n",
    "    col_mpc=cols_mpc[i]\n",
    "    col_qpt=cols_qpt[i]\n",
    "    #copy mpc and qpt results to the tmp df\n",
    "    tmp[col_mpc]=new_mpc[col_mpc].copy()\n",
    "    tmp[col_qpt]=new_qpt[col_qpt].copy()\n",
    "    #calculate difference of optimal points from cvxpy (elementwise)\n",
    "    error_mpc_cp+=abs(np.round(tmp[str(i)+\"cp\"],4)-np.round(tmp[col_mpc],4))\n",
    "    error_qpt_cp+=abs(np.round(tmp[str(i)+\"cp\"],4)-np.round(tmp[col_qpt],4))\n",
    "    #calculate difference of optimal points from gurobi (elementwise)\n",
    "    error_mpc_gur+=abs(np.round(tmp[str(i)+\"gur\"],4)-np.round(tmp[col_mpc],4))\n",
    "    error_qpt_gur+=abs(np.round(tmp[str(i)+\"gur\"],4)-np.round(tmp[col_qpt],4))\n",
    "    error_cp_gur+=abs(np.round(tmp[str(i)+\"gur\"],4)-np.round(tmp[str(i)+\"cp\"],4))\n",
    "\n",
    "#calculate optimum values and store them\n",
    "# cp_=torch.tensor(np.array(tmp[cols_cp])).view(nbatch,nx,1)\n",
    "# cp_opt=np.round(((0.5*torch.bmm(torch.transpose(cp_,dim0=2,dim1=1),\n",
    "#                                 torch.bmm(Q,cp_)))+torch.bmm(p.unsqueeze(-1).transpose(2,1),cp_)).view(-1).numpy(),6)\n",
    "tmp[\"cp-opt\"]=np.round(cvxpy_opt,4)#cp_opt\n",
    "tmp[\"gur-opt\"]=np.round(gurobi_opt,4)\n",
    "\n",
    "mpc=torch.tensor(np.array(tmp[cols_mpc])).view(nbatch,nx,1)\n",
    "mpc_opt=np.round(((0.5*torch.bmm(torch.transpose(mpc,dim0=2,dim1=1),\n",
    "                                 torch.bmm(Q,mpc)))+torch.bmm(p.unsqueeze(-1).transpose(2,1),mpc)).view(-1).numpy(),4)\n",
    "tmp[\"mpc-opt\"]=mpc_opt\n",
    "\n",
    "qpt=torch.tensor(np.array(tmp[cols_qpt])).view(nbatch,nx,1)\n",
    "qpt_opt=np.round(((0.5*torch.bmm(torch.transpose(qpt,dim0=2,dim1=1),\n",
    "                                 torch.bmm(Q,qpt)))+torch.bmm(p.unsqueeze(-1).transpose(2,1),qpt)).view(-1).numpy(),4)\n",
    "tmp[\"qpt-opt\"]=qpt_opt\n",
    "\n",
    "#store error values calculated in the for loop\n",
    "tmp[\"cp-mpc-error\"]=np.round(error_mpc_cp,6)\n",
    "tmp[\"cp-mpc-er_flag\"]=np.round(error_mpc_cp,6)!=0\n",
    "tmp[\"cp-qpt-error\"]=np.round(error_qpt_cp,6)\n",
    "tmp[\"cp-qpt-er_flag\"]=np.round(error_qpt_cp,6)!=0\n",
    "tmp[\"gur-mpc-error\"]=np.round(error_mpc_gur,6)\n",
    "tmp[\"gur-mpc-er_flag\"]=np.round(error_mpc_gur,6)!=0\n",
    "tmp[\"gur-qpt-error\"]=np.round(error_qpt_gur,6)\n",
    "tmp[\"gur-qpt-er_flag\"]=np.round(error_qpt_gur,6)!=0\n",
    "tmp[\"gur-cp-error\"]=np.round(error_cp_gur,6)\n",
    "tmp[\"gur-cp-er_flag\"]=np.round(error_cp_gur,6)!=0\n",
    "cols_order=[\"seed\",\"cp-opt\",\"mpc-opt\",\"qpt-opt\",'gur-opt',\"cp-mpc-error\",\n",
    "            \"cp-mpc-er_flag\",\"cp-qpt-error\",\"cp-qpt-er_flag\",\"gur-mpc-error\",\"gur-mpc-er_flag\",\n",
    "            \"gur-qpt-error\",\"gur-qpt-er_flag\",\"gur-cp-error\",\"gur-cp-er_flag\"]+ cols_cp+cols_mpc+cols_qpt+cols_gur\n",
    "tmp=tmp[cols_order]\n",
    "\n",
    "print(\"COMPARISON AGAINST GUROBI:\")\n",
    "print(\"No.of problems solved: \",len(tmp)-ge)\n",
    "results_gur=tmp[~tmp[\"seed\"].isin(gurobi_errors)].copy()\n",
    "print(len(results_gur))\n",
    "print(\"\\nNo.of errors from cvxpy: \",len(results_gur[results_gur['gur-cp-error']!=0]),\" (\",round(len(results_gur[results_gur['gur-cp-error']!=0])*100/len(results_gur),2),\"%)\")\n",
    "print(\"No.of errors from MPC \",len(results_gur[results_gur['gur-mpc-error']!=0]),\" (\",round(len(results_gur[results_gur['gur-mpc-error']!=0])*100/len(results_gur),2),\"%)\")\n",
    "print(\"No.of errors from qpth \",len(results_gur[results_gur['gur-qpt-error']!=0]),\" (\",round(len(results_gur[results_gur['gur-qpt-error']!=0])*100/len(results_gur),2),\"%)\")\n",
    "print(\"______________________________________________\")\n",
    "print(\"\\n\\nCOMPARISON AGAINST CVXPY:\")\n",
    "print(\"No.of problems solved: \",len(tmp)-ce)\n",
    "cvxpy_errors=np.unique(cvxpy_errors)\n",
    "results_cp=tmp[~tmp[\"seed\"].isin(cvxpy_errors)].copy()\n",
    "print(len(results_cp))\n",
    "print(\"No.of errors from MPC: \",len(results_cp[results_cp['cp-mpc-error']!=0]),\" (\",round(len(results_cp[results_cp['cp-mpc-error']!=0])*100/len(results_cp),2),\"%)\")\n",
    "print(\"No.of errors from qpth: \",len(results_cp[results_cp['cp-qpt-error']!=0]),\" (\",round(len(results_cp[results_cp['cp-qpt-error']!=0])*100/len(results_cp),2),\"%)\")\n",
    "print(\"______________________________________________\")\n",
    "print(\"\\n\\nTIME COMPARISON:\")\n",
    "print(\"gurobi time: \", gurobi_time)\n",
    "print(\"cvxpy time: \", cvxpy_time)\n",
    "print(\"mpc time: \", mpc_time)\n",
    "print(\"qpth time: \", qpth_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0mpc</th>\n",
       "      <th>1mpc</th>\n",
       "      <th>2mpc</th>\n",
       "      <th>3mpc</th>\n",
       "      <th>4mpc</th>\n",
       "      <th>5mpc</th>\n",
       "      <th>0gur</th>\n",
       "      <th>1gur</th>\n",
       "      <th>2gur</th>\n",
       "      <th>3gur</th>\n",
       "      <th>4gur</th>\n",
       "      <th>5gur</th>\n",
       "      <th>mpc-opt</th>\n",
       "      <th>gur-opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.4662</td>\n",
       "      <td>-8.3199</td>\n",
       "      <td>-3.6869</td>\n",
       "      <td>4.9170</td>\n",
       "      <td>3.8718</td>\n",
       "      <td>-1.1078</td>\n",
       "      <td>1.4662</td>\n",
       "      <td>-8.3199</td>\n",
       "      <td>-3.6869</td>\n",
       "      <td>4.9170</td>\n",
       "      <td>3.8717</td>\n",
       "      <td>-1.1078</td>\n",
       "      <td>-29.1117</td>\n",
       "      <td>-29.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.4531</td>\n",
       "      <td>-20.7534</td>\n",
       "      <td>18.3509</td>\n",
       "      <td>-3.7013</td>\n",
       "      <td>13.9057</td>\n",
       "      <td>-13.7577</td>\n",
       "      <td>10.4531</td>\n",
       "      <td>-20.7534</td>\n",
       "      <td>18.3510</td>\n",
       "      <td>-3.7013</td>\n",
       "      <td>13.9057</td>\n",
       "      <td>-13.7577</td>\n",
       "      <td>777.5351</td>\n",
       "      <td>777.5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.2617</td>\n",
       "      <td>-0.3377</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>1.1425</td>\n",
       "      <td>-0.1739</td>\n",
       "      <td>-0.0779</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>8.5608</td>\n",
       "      <td>8.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>76.0083</td>\n",
       "      <td>-118.5240</td>\n",
       "      <td>144.1918</td>\n",
       "      <td>-33.2707</td>\n",
       "      <td>28.0332</td>\n",
       "      <td>-112.1791</td>\n",
       "      <td>76.0096</td>\n",
       "      <td>-118.5259</td>\n",
       "      <td>144.1941</td>\n",
       "      <td>-33.2712</td>\n",
       "      <td>28.0336</td>\n",
       "      <td>-112.1809</td>\n",
       "      <td>138711.6857</td>\n",
       "      <td>138716.1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>11.3557</td>\n",
       "      <td>-18.5234</td>\n",
       "      <td>109.0042</td>\n",
       "      <td>3.0035</td>\n",
       "      <td>-107.7981</td>\n",
       "      <td>-1.3099</td>\n",
       "      <td>11.3558</td>\n",
       "      <td>-18.5236</td>\n",
       "      <td>109.0049</td>\n",
       "      <td>3.0035</td>\n",
       "      <td>-107.7989</td>\n",
       "      <td>-1.3099</td>\n",
       "      <td>6183.8701</td>\n",
       "      <td>6183.9577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-8.7610</td>\n",
       "      <td>7.1807</td>\n",
       "      <td>9.5307</td>\n",
       "      <td>9.4019</td>\n",
       "      <td>4.2929</td>\n",
       "      <td>-8.5675</td>\n",
       "      <td>-8.7610</td>\n",
       "      <td>7.1807</td>\n",
       "      <td>9.5308</td>\n",
       "      <td>9.4019</td>\n",
       "      <td>4.2929</td>\n",
       "      <td>-8.5676</td>\n",
       "      <td>518.8764</td>\n",
       "      <td>518.8787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>57.7708</td>\n",
       "      <td>-89.5180</td>\n",
       "      <td>47.5900</td>\n",
       "      <td>11.4830</td>\n",
       "      <td>77.8867</td>\n",
       "      <td>-64.2987</td>\n",
       "      <td>57.7709</td>\n",
       "      <td>-89.5181</td>\n",
       "      <td>47.5901</td>\n",
       "      <td>11.4830</td>\n",
       "      <td>77.8868</td>\n",
       "      <td>-64.2988</td>\n",
       "      <td>7703.0869</td>\n",
       "      <td>7703.1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>13.8624</td>\n",
       "      <td>-15.7927</td>\n",
       "      <td>-39.6885</td>\n",
       "      <td>-46.5327</td>\n",
       "      <td>37.1927</td>\n",
       "      <td>52.6058</td>\n",
       "      <td>13.8623</td>\n",
       "      <td>-15.7926</td>\n",
       "      <td>-39.6882</td>\n",
       "      <td>-46.5324</td>\n",
       "      <td>37.1925</td>\n",
       "      <td>52.6055</td>\n",
       "      <td>4581.0270</td>\n",
       "      <td>4580.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>12.1733</td>\n",
       "      <td>-12.7420</td>\n",
       "      <td>-1.8534</td>\n",
       "      <td>5.3629</td>\n",
       "      <td>-5.3066</td>\n",
       "      <td>4.1962</td>\n",
       "      <td>12.1732</td>\n",
       "      <td>-12.7420</td>\n",
       "      <td>-1.8534</td>\n",
       "      <td>5.3629</td>\n",
       "      <td>-5.3066</td>\n",
       "      <td>4.1962</td>\n",
       "      <td>252.0762</td>\n",
       "      <td>252.0741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>25.9150</td>\n",
       "      <td>1.5828</td>\n",
       "      <td>8.3054</td>\n",
       "      <td>-1.0773</td>\n",
       "      <td>-25.2579</td>\n",
       "      <td>5.8040</td>\n",
       "      <td>25.9151</td>\n",
       "      <td>1.5828</td>\n",
       "      <td>8.3054</td>\n",
       "      <td>-1.0773</td>\n",
       "      <td>-25.2580</td>\n",
       "      <td>5.8040</td>\n",
       "      <td>2255.6855</td>\n",
       "      <td>2255.6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>3.2483</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>-3.0449</td>\n",
       "      <td>-0.0964</td>\n",
       "      <td>1.0818</td>\n",
       "      <td>-1.9684</td>\n",
       "      <td>3.2483</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>-3.0450</td>\n",
       "      <td>-0.0964</td>\n",
       "      <td>1.0818</td>\n",
       "      <td>-1.9684</td>\n",
       "      <td>-11.7725</td>\n",
       "      <td>-11.7727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.3725</td>\n",
       "      <td>1.0960</td>\n",
       "      <td>6.8093</td>\n",
       "      <td>-5.3361</td>\n",
       "      <td>-4.6253</td>\n",
       "      <td>-4.2030</td>\n",
       "      <td>-0.3725</td>\n",
       "      <td>1.0961</td>\n",
       "      <td>6.8093</td>\n",
       "      <td>-5.3361</td>\n",
       "      <td>-4.6253</td>\n",
       "      <td>-4.2029</td>\n",
       "      <td>-21.4242</td>\n",
       "      <td>-21.4239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>-1.9216</td>\n",
       "      <td>-5.5924</td>\n",
       "      <td>1.7253</td>\n",
       "      <td>8.9453</td>\n",
       "      <td>-7.1401</td>\n",
       "      <td>-1.7062</td>\n",
       "      <td>-1.9216</td>\n",
       "      <td>-5.5924</td>\n",
       "      <td>1.7253</td>\n",
       "      <td>8.9453</td>\n",
       "      <td>-7.1400</td>\n",
       "      <td>-1.7062</td>\n",
       "      <td>-50.2007</td>\n",
       "      <td>-50.2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>5.8456</td>\n",
       "      <td>3.1780</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>-3.8144</td>\n",
       "      <td>-2.8896</td>\n",
       "      <td>-2.8219</td>\n",
       "      <td>5.8456</td>\n",
       "      <td>3.1780</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>-3.8143</td>\n",
       "      <td>-2.8896</td>\n",
       "      <td>-2.8219</td>\n",
       "      <td>20.3569</td>\n",
       "      <td>20.3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>12.6737</td>\n",
       "      <td>-11.6687</td>\n",
       "      <td>27.5114</td>\n",
       "      <td>6.1449</td>\n",
       "      <td>-15.1278</td>\n",
       "      <td>-17.4238</td>\n",
       "      <td>12.6737</td>\n",
       "      <td>-11.6687</td>\n",
       "      <td>27.5115</td>\n",
       "      <td>6.1449</td>\n",
       "      <td>-15.1278</td>\n",
       "      <td>-17.4238</td>\n",
       "      <td>1202.5392</td>\n",
       "      <td>1202.5370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>-0.2552</td>\n",
       "      <td>3.8806</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>-3.4339</td>\n",
       "      <td>1.7529</td>\n",
       "      <td>1.5661</td>\n",
       "      <td>-0.2552</td>\n",
       "      <td>3.8806</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>-3.4338</td>\n",
       "      <td>1.7529</td>\n",
       "      <td>1.5661</td>\n",
       "      <td>17.6138</td>\n",
       "      <td>17.6142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.0632</td>\n",
       "      <td>-0.7521</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-0.7521</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>3.0525</td>\n",
       "      <td>3.0523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>16.0392</td>\n",
       "      <td>8.6670</td>\n",
       "      <td>3.4734</td>\n",
       "      <td>2.8858</td>\n",
       "      <td>-31.0988</td>\n",
       "      <td>23.6346</td>\n",
       "      <td>16.0391</td>\n",
       "      <td>8.6670</td>\n",
       "      <td>3.4734</td>\n",
       "      <td>2.8858</td>\n",
       "      <td>-31.0986</td>\n",
       "      <td>23.6345</td>\n",
       "      <td>997.9133</td>\n",
       "      <td>997.9069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>-0.7584</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.4777</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>-0.7739</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.2423</td>\n",
       "      <td>3.4101</td>\n",
       "      <td>3.2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.0335</td>\n",
       "      <td>1.1437</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>-2.6325</td>\n",
       "      <td>-1.9740</td>\n",
       "      <td>2.8412</td>\n",
       "      <td>1.0335</td>\n",
       "      <td>1.1437</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>-2.6324</td>\n",
       "      <td>-1.9740</td>\n",
       "      <td>2.8412</td>\n",
       "      <td>14.6679</td>\n",
       "      <td>14.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1.5624</td>\n",
       "      <td>-1.9087</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>-0.0739</td>\n",
       "      <td>2.9029</td>\n",
       "      <td>-2.6684</td>\n",
       "      <td>1.5624</td>\n",
       "      <td>-1.9087</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>-0.0739</td>\n",
       "      <td>2.9028</td>\n",
       "      <td>-2.6684</td>\n",
       "      <td>-4.5576</td>\n",
       "      <td>-4.5583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2.4166</td>\n",
       "      <td>-0.8306</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>-4.0173</td>\n",
       "      <td>1.2303</td>\n",
       "      <td>2.4165</td>\n",
       "      <td>-0.8306</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>-4.0173</td>\n",
       "      <td>1.2303</td>\n",
       "      <td>-5.0593</td>\n",
       "      <td>-5.0591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0mpc      1mpc      2mpc     3mpc      4mpc      5mpc     0gur  \\\n",
       "8     1.4662   -8.3199   -3.6869   4.9170    3.8718   -1.1078   1.4662   \n",
       "14   10.4531  -20.7534   18.3509  -3.7013   13.9057  -13.7577  10.4531   \n",
       "89    1.2617   -0.3377   -0.0487   0.3651    0.2907    0.6700   1.1425   \n",
       "116  76.0083 -118.5240  144.1918 -33.2707   28.0332 -112.1791  76.0096   \n",
       "142  11.3557  -18.5234  109.0042   3.0035 -107.7981   -1.3099  11.3558   \n",
       "162  -8.7610    7.1807    9.5307   9.4019    4.2929   -8.5675  -8.7610   \n",
       "203  57.7708  -89.5180   47.5900  11.4830   77.8867  -64.2987  57.7709   \n",
       "212  13.8624  -15.7927  -39.6885 -46.5327   37.1927   52.6058  13.8623   \n",
       "226  12.1733  -12.7420   -1.8534   5.3629   -5.3066    4.1962  12.1732   \n",
       "244  25.9150    1.5828    8.3054  -1.0773  -25.2579    5.8040  25.9151   \n",
       "420   3.2483    0.2143   -3.0449  -0.0964    1.0818   -1.9684   3.2483   \n",
       "526  -0.3725    1.0960    6.8093  -5.3361   -4.6253   -4.2030  -0.3725   \n",
       "577  -1.9216   -5.5924    1.7253   8.9453   -7.1401   -1.7062  -1.9216   \n",
       "620   5.8456    3.1780    0.7510  -3.8144   -2.8896   -2.8219   5.8456   \n",
       "671  12.6737  -11.6687   27.5114   6.1449  -15.1278  -17.4238  12.6737   \n",
       "770  -0.2552    3.8806    0.4433  -3.4339    1.7529    1.5661  -0.2552   \n",
       "807   0.0632   -0.7521    0.3624  -0.0016    0.6996    0.3033   0.0633   \n",
       "874  16.0392    8.6670    3.4734   2.8858  -31.0988   23.6346  16.0391   \n",
       "876  -0.7584    0.0250    0.0397   0.4777    1.0571    0.1844  -0.7739   \n",
       "880   1.0335    1.1437    0.1374  -2.6325   -1.9740    2.8412   1.0335   \n",
       "884   1.5624   -1.9087   -0.3412  -0.0739    2.9029   -2.6684   1.5624   \n",
       "910   2.4166   -0.8306    0.8560   0.8293   -4.0173    1.2303   2.4165   \n",
       "\n",
       "         1gur      2gur     3gur      4gur      5gur      mpc-opt      gur-opt  \n",
       "8     -8.3199   -3.6869   4.9170    3.8717   -1.1078     -29.1117     -29.1125  \n",
       "14   -20.7534   18.3510  -3.7013   13.9057  -13.7577     777.5351     777.5372  \n",
       "89    -0.1739   -0.0779   0.2549    0.3138    0.7019       8.5608       8.4286  \n",
       "116 -118.5259  144.1941 -33.2712   28.0336 -112.1809  138711.6857  138716.1654  \n",
       "142  -18.5236  109.0049   3.0035 -107.7989   -1.3099    6183.8701    6183.9577  \n",
       "162    7.1807    9.5308   9.4019    4.2929   -8.5676     518.8764     518.8787  \n",
       "203  -89.5181   47.5901  11.4830   77.8868  -64.2988    7703.0869    7703.1084  \n",
       "212  -15.7926  -39.6882 -46.5324   37.1925   52.6055    4581.0270    4580.9706  \n",
       "226  -12.7420   -1.8534   5.3629   -5.3066    4.1962     252.0762     252.0741  \n",
       "244    1.5828    8.3054  -1.0773  -25.2580    5.8040    2255.6855    2255.6995  \n",
       "420    0.2143   -3.0450  -0.0964    1.0818   -1.9684     -11.7725     -11.7727  \n",
       "526    1.0961    6.8093  -5.3361   -4.6253   -4.2029     -21.4242     -21.4239  \n",
       "577   -5.5924    1.7253   8.9453   -7.1400   -1.7062     -50.2007     -50.2009  \n",
       "620    3.1780    0.7510  -3.8143   -2.8896   -2.8219      20.3569      20.3567  \n",
       "671  -11.6687   27.5115   6.1449  -15.1278  -17.4238    1202.5392    1202.5370  \n",
       "770    3.8806    0.4433  -3.4338    1.7529    1.5661      17.6138      17.6142  \n",
       "807   -0.7521    0.3624  -0.0016    0.6996    0.3033       3.0525       3.0523  \n",
       "874    8.6670    3.4734   2.8858  -31.0986   23.6345     997.9133     997.9069  \n",
       "876    0.1515   -0.0147   0.3985    0.9501    0.2423       3.4101       3.2589  \n",
       "880    1.1437    0.1374  -2.6324   -1.9740    2.8412      14.6679      14.6684  \n",
       "884   -1.9087   -0.3412  -0.0739    2.9028   -2.6684      -4.5576      -4.5583  \n",
       "910   -0.8306    0.8560   0.8293   -4.0173    1.2303      -5.0593      -5.0591  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=results_gur.loc[results_gur[\"gur-mpc-er_flag\"],np.append(cols_mpc,np.append(cols_gur,[\"mpc-opt\",\"gur-opt\"])) ]\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[u[\"mpc-opt\"]<u[\"gur-opt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[u[\"mpc-opt\"]>u[\"gur-opt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ff5a0e942d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_spd_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "Q.append(make_spd_matrix(nx,random_state=seed).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57590251,  0.40188819,  0.18131191, -0.01467761,  0.56187803,\n",
       "        -0.39983129,  0.40188819,  1.95489793,  0.285852  ,  0.01657491,\n",
       "         1.9807648 , -1.01279744,  0.18131191,  0.285852  ,  0.64411307,\n",
       "         0.00754676,  0.85436686, -0.44048994, -0.01467761,  0.01657491,\n",
       "         0.00754676,  0.47343564,  0.24924825,  0.03113005,  0.56187803,\n",
       "         1.9807648 ,  0.85436686,  0.24924825,  4.03732017, -1.96538966,\n",
       "        -0.39983129, -1.01279744, -0.44048994,  0.03113005, -1.96538966,\n",
       "         1.52648933]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_spd_matrix(nx,random_state=seed).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.189462708300947,\n",
       " 1.9887660413572206,\n",
       " 0.4062201814057498,\n",
       " 8.64396409049604,\n",
       " 0.2875741497702511,\n",
       " 0.34007172515212236]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.random()*10 for i in range(nx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "authorship_tag": "ABX9TyMvIxAPtWnKQ4qqKTOR0z9Q",
   "include_colab_link": true,
   "name": "performance_comparison.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
