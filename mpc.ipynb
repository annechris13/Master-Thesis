{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mpc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY/Fsmd5dJpE3TOC4EF7H4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annechris13/Master-Thesis/blob/master/mpc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW72Blyw1922",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('error')\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBiXLGmPd2K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5f0LYg6co6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('gdrive/My Drive/test_cases.csv')\n",
        "# seeds=df[\"seed\"].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGYHKVEEFIUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !pip install import-ipynb\n",
        "# import import_ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZPjwoLFM9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd \"/content/gdrive/My Drive/Colab Notebooks\"\n",
        "# import mpc_class\n",
        "# # %ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqs1lyCtFmJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import qpth_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lpy6-HQ2ErN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ip=0\n",
        "# #example problem - 2 batches , 2 variable qp\n",
        "# nbatch=2\n",
        "# nBatch=nbatch\n",
        "# nx=2\n",
        "# nineq=2\n",
        "# neq=1\n",
        "# #to do: extract dimensions from problem parameters + check/add batch dimension\n",
        "# Q=torch.tensor([[4,1,1,2],[6,2,2,2]]).view(nbatch,nx,nx).type(torch.DoubleTensor)\n",
        "# p=torch.tensor([[1,1],[1,6]]).view(nbatch,nx).type(torch.DoubleTensor)\n",
        "# G=torch.tensor([[-1,0,0,-1],[-1,0,0,-1]]).view(nbatch,nineq,nx).type(torch.DoubleTensor)\n",
        "# h=torch.tensor([[0,0],[0,0]]).view(nbatch,nineq).type(torch.DoubleTensor)\n",
        "# A=torch.tensor([[1,1],[2,3]]).view(nbatch,neq,nx).type(torch.DoubleTensor)\n",
        "# b=torch.tensor([[1],[4]]).view(nbatch,neq).type(torch.DoubleTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk8sm1r0dWD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ip=\"csv\"\n",
        "nbatch=len(df)\n",
        "nx=6\n",
        "nineq=6\n",
        "neq=3\n",
        "Q=[]\n",
        "p=[]\n",
        "G=[]\n",
        "h=[]\n",
        "A=[]\n",
        "b=[]\n",
        "for i in range(nbatch):\n",
        "  seed=int(df[\"seed\"][i])\n",
        "  random.seed(seed)\n",
        "  Q.append(make_spd_matrix(nx,random_state=seed).reshape(1,-1))\n",
        "  p.append([random.randint(0,9) for i in range(nx)])#.astype(float))\n",
        "  G.append([random.randint(0,9)*((-1)**random.randint(0,1)) for i in range(nineq*nx)])#.astype(float))\n",
        "  h.append([0 for i in range(nineq)])#.astype(float))\n",
        "  A.append([random.randint(0,9) for i in range(neq*nx)])#.astype(float))\n",
        "  b.append([random.randint(0,9) for i in range(neq)])#.astype(float)  )\n",
        "\n",
        "Q=torch.tensor(Q).view(nbatch,nx,nx).type(torch.DoubleTensor)\n",
        "p=torch.tensor(p).view(nbatch,nx).type(torch.DoubleTensor)\n",
        "G=torch.tensor(G).view(nbatch,nineq,nx).type(torch.DoubleTensor)\n",
        "h=torch.tensor(h).view(nbatch,nineq).type(torch.DoubleTensor)\n",
        "A=torch.tensor(A).view(nbatch,neq,nx).type(torch.DoubleTensor)\n",
        "b=torch.tensor(b).view(nbatch,neq).type(torch.DoubleTensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OBoEaK52Szk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if Q is psd:\n",
        "for i in range(nbatch):\n",
        "  e,_=torch.eig(Q[i])\n",
        "  if not torch.all(e[:,0]>0):\n",
        "    raise RuntimeError(\"Q is not PD\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb-4GMN2cHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lu_hack(x):\n",
        "    data, pivots = x.lu(pivot=not x.is_cuda)\n",
        "    if x.is_cuda:\n",
        "        if x.ndimension() == 2:\n",
        "            pivots = torch.arange(1, 1+x.size(0)).int().cuda()\n",
        "        elif x.ndimension() == 3:\n",
        "            pivots = torch.arange(\n",
        "                1, 1+x.size(1),\n",
        "            ).unsqueeze(0).repeat(x.size(0), 1).int().cuda()\n",
        "        else:\n",
        "            assert False\n",
        "    return (data, pivots)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFQ6FkJ62yFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bdiag(d):\n",
        "    nBatch, sz, _ = d.size()\n",
        "    D = torch.zeros(nBatch, sz, sz).type_as(d)\n",
        "    I = torch.eye(sz).repeat(nBatch, 1, 1).type_as(d).bool()\n",
        "    D[I] = d.squeeze().view(-1)\n",
        "    return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNYAn_fc23kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Hessian(Q,G,A):\n",
        "    nbatch,nineq,nx=G.size()\n",
        "    neq=A.size()[1]\n",
        "    B1=torch.zeros(nbatch,nx+nineq,nx+nineq).type_as(Q)\n",
        "    B3=torch.zeros(nbatch,neq+nineq,nx+nineq).type_as(Q)\n",
        "    B4=torch.zeros(nbatch,neq+nineq,neq+nineq).type_as(Q)\n",
        "\n",
        "    B1[:,:nx,:nx]=Q\n",
        "    B1[:,-nineq:,-nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B3[:,:nineq,:nx]=G\n",
        "    B3[:,-neq:,:nx]=A\n",
        "    B3[:,:nineq,nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B2=torch.transpose(B3, dim0=2, dim1=1)\n",
        "\n",
        "    H=torch.cat((torch.cat((B1,B2),dim=2),torch.cat((B3,B4),dim=2)),dim=1)\n",
        "  \n",
        "    return H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnl836f27g8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def solve_kkt(H,rx,rs,rz,ry,d=None):\n",
        "    if d!=None:\n",
        "      D=bdiag(d)\n",
        "      H[:,nx:nx+nineq,nx:nx+nineq]=D\n",
        "    # print(\"H: \",H)\n",
        "    H_lu,H_piv= lu_hack(H)\n",
        "    F=torch.cat((rx,rs,rz,ry), dim=1)\n",
        "    step=F.lu_solve(H_lu,H_piv)\n",
        "\n",
        "    rx=step[:,:nx,:]\n",
        "    rs=step[:,nx:nx+nineq,:]\n",
        "    rz=step[:,nx+nineq:-neq,:]\n",
        "    ry=step[:,-neq:,:]\n",
        "    return(rx,rs,rz,ry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGgtol371pyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_initial(z):\n",
        "      nbatch,_,_=z.size()\n",
        "      dz=torch.ones(z.size()).type_as(z)\n",
        "      alpha=torch.tensor([]).type_as(z)\n",
        "      for b in range(nbatch):\n",
        "        step=torch.tensor([-0.1]).type_as(z)\n",
        "        z_=z[b,:,:]\n",
        "        dz_=dz[b,:,:]\n",
        "        while True:\n",
        "          if (z_+step*dz_ >0).all():\n",
        "            if step<0:\n",
        "              alpha=torch.cat((alpha,torch.tensor([0]).type_as(z)))\n",
        "            else:\n",
        "              alpha=torch.cat((alpha,1+step))\n",
        "            break\n",
        "          else:\n",
        "            step=step+0.1\n",
        "      return alpha.view(nbatch,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0e1u9MNug7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_step(v,dv):\n",
        "      #TO DO: find efficient and accurate line search algorithm\n",
        "      nbatch,_,_=v.size()\n",
        "      alpha=torch.tensor([]).type_as(v)\n",
        "      for b in range(nbatch):\n",
        "        step=torch.tensor([1]).type_as(v)\n",
        "        v_=v[b,:,:]\n",
        "        dv_=dv[b,:,:]\n",
        "        while step>0:\n",
        "          if (v_+step*dv_ >=0).all() or step==0:\n",
        "            alpha=torch.cat((alpha,step))\n",
        "            break\n",
        "          else:\n",
        "            step=step-0.1\n",
        "        if(step<0):\n",
        "          alpha=torch.cat((alpha,torch.tensor([0]).type_as(v)))\n",
        "      # print(alpha.view(nbatch,1,1).size())\n",
        "      return alpha.view(nbatch,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqm4QOzb2wan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using this get_step function results in step size nan \n",
        "#uncomment this cell to see the result\n",
        "# def get_step(v, dv):\n",
        "#     a = -v / dv\n",
        "#     a[dv > 0] = max(1.0, a.max())\n",
        "#     # print(a.min(1)[0].unsqueeze(2).size())\n",
        "#     return a.min(1)[0].unsqueeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MqWmBrLrgYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mpc(Q,G,A,p,b,h,x,s,z,y, max_iter=20):\n",
        "    H=get_Hessian(Q,G,A)\n",
        "    A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "    G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "    count=0\n",
        "    bat=np.array([i for i in range(nbatch)])\n",
        "    for i in range(max_iter):\n",
        "        # print(\"iteration: \",i)\n",
        "        rx= -(torch.bmm(A_T,y)+torch.bmm(G_T,z)+torch.bmm(Q,x)+p.unsqueeze(2))\n",
        "        rs=-z\n",
        "        rz=-(torch.bmm(G,x)+s-h.unsqueeze(2))\n",
        "        ry=-(torch.bmm(A,x)-b.unsqueeze(2))\n",
        "        d=z/s\n",
        "        mu=torch.abs(torch.bmm(torch.transpose(s,dim0=2,dim1=1),z).sum(1))\n",
        "        pri_resid=torch.abs(rx)\n",
        "        dual_1_resid=torch.abs(rz)\n",
        "        dual_2_resid=torch.abs(ry)\n",
        "        if (i%4==0):\n",
        "          log=((pri_resid.sum(1)<1e-12)*(dual_1_resid.sum(1)<1e-12)*(dual_2_resid.sum(1)<1e-12)*(mu<1e-12)).squeeze(1).numpy().astype(bool)\n",
        "          # print(\"already converged: \",bat[log] )\n",
        "\n",
        "        resids=np.array([pri_resid.max(),mu.max(),dual_1_resid.max(),dual_2_resid.max()])\n",
        "        try:\n",
        "          if (resids<1e-12).all():\n",
        "            print(\"Early exit at iteration no:\",i)\n",
        "            return(x,s,z,y)\n",
        "        except:\n",
        "          print(\"primal residula nan for problem: \",bat[torch.isnan(pri_resid.sum(1)).squeeze(1)])\n",
        "          print(\"step size nan for problem: \",bat[torch.isnan(alpha).squeeze(1).squeeze()])\n",
        "          raise RuntimeError(\"invalid res\")\n",
        "        \n",
        "        #affine step calculation\n",
        "        dx_aff,ds_aff,dz_aff,dy_aff=solve_kkt(H,rx,rs,rz,ry,d)\n",
        "        #affine step size calculation\n",
        "        alpha = torch.min(get_step(z, dz_aff),get_step(s, ds_aff))\n",
        "        # get_step_qpth(z,dz_aff)\n",
        "        # get_step_qpth(s,ds_aff)\n",
        "        #affine updates for s and z\n",
        "        s_aff=s+alpha*ds_aff\n",
        "        z_aff=z+alpha*dz_aff\n",
        "        mu_aff=torch.abs(torch.bmm(torch.transpose(s_aff,dim0=2,dim1=1),z_aff).sum(1))\n",
        "        \n",
        "        #find sigma for centering in the direction of mu\n",
        "        sigma=(mu_aff/mu)**3\n",
        "\n",
        "        #find centering+correction steps\n",
        "        rx=torch.zeros(rx.size()).type_as(Q)\n",
        "        rs=((sigma*mu).unsqueeze(2).repeat(1,nineq,1)-ds_aff*dz_aff)/s\n",
        "        rz=torch.zeros(rz.size()).type_as(Q)\n",
        "        ry=torch.zeros(ry.size()).type_as(Q)\n",
        "        dx_cor,ds_cor,dz_cor,dy_cor=solve_kkt(H,rx,rs,rz,ry,d)\n",
        "\n",
        "        dx=dx_aff+dx_cor\n",
        "        ds=ds_aff+ds_cor\n",
        "        dz=dz_aff+dz_cor\n",
        "        dy=dy_aff+dy_cor\n",
        "        # find update step size\n",
        "        alpha = torch.min(torch.ones(nbatch).type_as(Q).view(nbatch,1,1),0.99*torch.min(get_step(z, dz),get_step(s, ds)))\n",
        "        # get_step_qpth(z,dz)\n",
        "        # get_step_qpth(s,ds)\n",
        "        # update\n",
        "        x+=alpha*dx\n",
        "        s+=alpha*ds\n",
        "        z+=alpha*dz\n",
        "        y+=alpha*dy\n",
        "\n",
        "        if(i==max_iter-1 and (resids>1e-10).any()):\n",
        "          print(\"no of mu not converged: \",len(mu[mu>1e-10]))\n",
        "          print(\"no of primal residual not converged: \",len(pri_resid[pri_resid>1e-10]))\n",
        "          print(\"no of dual residual 1 not converged: \",len(dual_1_resid[dual_1_resid>1e-10]))\n",
        "          print(\"no of dual residual 2 not converged: \",len(dual_2_resid[dual_2_resid>1e-10]))\n",
        "          print(\"Residuals not converged, need more itrations\")\n",
        "\n",
        "    return(x,s,z,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S63UdqzF6cTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def opt(Q,p,G,h,A,b):\n",
        "  H=get_Hessian(Q,G,A)\n",
        "  A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "  G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "  #initial solution\n",
        "  x,s,z,y=solve_kkt(H,-p.unsqueeze(2),torch.zeros(nbatch,nineq).unsqueeze(2).type_as(Q),h.unsqueeze(2),b.unsqueeze(2))\n",
        "  alpha_p=get_initial(-z)\n",
        "  alpha_d=get_initial(z)\n",
        "  s=-z+alpha_p*(torch.ones(z.size()).type_as(z))\n",
        "  z=z+alpha_d*(torch.ones(z.size()).type_as(z))\n",
        "  #main iterations\n",
        "  start = time.time()\n",
        "  x,s,z,y=mpc(Q,G,A,p,b,h,x,s,z,y,30)\n",
        "  op_val=0.5*torch.bmm(torch.transpose(x,dim0=2,dim1=1),torch.bmm(Q,x))+torch.bmm(torch.transpose(p.unsqueeze(2),dim0=2,dim1=1),x)\n",
        "  t = time.time() - start\n",
        "  print(t)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGo9chlL6hp9",
        "colab_type": "code",
        "outputId": "da57b541-88c7-4e6b-d598-8cefb6389f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x=opt(Q,p,G,h,A,b)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of mu not converged:  6\n",
            "no of primal residual not converged:  34\n",
            "no of dual residual 1 not converged:  36\n",
            "no of dual residual 2 not converged:  0\n",
            "Residuals not converged, need more itrations\n",
            "10.209073305130005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYAO8ThCy5YF",
        "colab_type": "code",
        "outputId": "5cfe9b0c-c5d8-4295-8d67-ae81cd6ed80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "if ip!=\"csv\":\n",
        "    print(\"optimal point: \\n\", x.numpy().reshape(nbatch,-1))\n",
        "    print(\"\\noptimal objective value: \\n\", op_val.numpy().reshape(nbatch,-1))\n",
        "\n",
        "if ip==\"csv\":\n",
        "    cols=[str(i)+\"mpc\" for i in range(nx)]\n",
        "    error_cp=np.zeros(nbatch)\n",
        "    error_qp=np.zeros(nbatch)\n",
        "    new=pd.DataFrame(x.numpy().round(6).reshape(nbatch,-1),columns=cols)\n",
        "    tmp=df.copy()\n",
        "    for i,col in enumerate(cols):\n",
        "      tmp[col]=new[col].copy()\n",
        "      error_cp+=np.round(tmp[str(i)+\"cp\"],6)-np.round(tmp[col],6)\n",
        "      error_qp+=np.round(tmp[str(i)+\"qpt\"],6)-np.round(tmp[col],6)\n",
        "\n",
        "    tmp[\"cp-mpc-error\"]=error_cp\n",
        "    tmp[\"cp-mpc-er_flag\"]=error_cp!=0\n",
        "    tmp[\"qpt-mpc-error\"]=error_qp\n",
        "    tmp[\"qpt-mpc-er_flag\"]=error_qp!=0\n",
        "    print(\"No.of problems solved: \",len(tmp))\n",
        "    print(\"No.of errors from MPC Method: \",len(error_cp[error_cp!=0]),\" (\",round(len(error_cp[error_cp!=0])*100/len(tmp),2),\")\")\n",
        "    print(\"No.of errors from qpth: \",len(tmp[tmp[\"cp-qpt-er_flag\"]]),\" (\",round(len(tmp[tmp[\"cp-qpt-er_flag\"]])*100/len(tmp),2),\")\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of problems solved:  639\n",
            "No.of errors from MPC Method:  6  ( 0.94 )\n",
            "No.of errors from qpth:  22  ( 3.44 )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmbRf-ZF3tTd",
        "colab_type": "text"
      },
      "source": [
        "The MPC method produces few no.of inaccurate results (0.94%) - also very less compared to qpth. (when using a step size decrement of 0.01 (instead of 0.1) in the get_step(), the inaacuracy reduces to just one problem(0.16%); also most of the execution time is spend on this function. This drives the focus on to a more accurate line search algorithm.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsvQdtUJ3e90",
        "colab_type": "code",
        "outputId": "aff17ce6-d50e-4966-b6da-03de9978308c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "tmp[tmp[\"cp-mpc-er_flag\"]]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>seed</th>\n",
              "      <th>0cp</th>\n",
              "      <th>1cp</th>\n",
              "      <th>2cp</th>\n",
              "      <th>3cp</th>\n",
              "      <th>4cp</th>\n",
              "      <th>5cp</th>\n",
              "      <th>0qpt</th>\n",
              "      <th>1qpt</th>\n",
              "      <th>2qpt</th>\n",
              "      <th>3qpt</th>\n",
              "      <th>4qpt</th>\n",
              "      <th>5qpt</th>\n",
              "      <th>cp-qpt-error</th>\n",
              "      <th>cp-qpt-er_flag</th>\n",
              "      <th>0mpc</th>\n",
              "      <th>1mpc</th>\n",
              "      <th>2mpc</th>\n",
              "      <th>3mpc</th>\n",
              "      <th>4mpc</th>\n",
              "      <th>5mpc</th>\n",
              "      <th>cp-mpc-error</th>\n",
              "      <th>cp-mpc-er_flag</th>\n",
              "      <th>qpt-mpc-error</th>\n",
              "      <th>qpt-mpc-er_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>190</td>\n",
              "      <td>3150.0</td>\n",
              "      <td>-18.274590</td>\n",
              "      <td>-27.152459</td>\n",
              "      <td>8.861475</td>\n",
              "      <td>9.636066</td>\n",
              "      <td>7.383607</td>\n",
              "      <td>7.514754</td>\n",
              "      <td>0.315030</td>\n",
              "      <td>-0.230616</td>\n",
              "      <td>0.209725</td>\n",
              "      <td>0.116471</td>\n",
              "      <td>0.004432</td>\n",
              "      <td>0.509967</td>\n",
              "      <td>-12.956156</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.028307</td>\n",
              "      <td>-0.744350</td>\n",
              "      <td>0.475821</td>\n",
              "      <td>0.248313</td>\n",
              "      <td>0.102588</td>\n",
              "      <td>0.595924</td>\n",
              "      <td>-12.681136</td>\n",
              "      <td>True</td>\n",
              "      <td>0.275020</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>285</td>\n",
              "      <td>4590.0</td>\n",
              "      <td>3.362302</td>\n",
              "      <td>-1.489500</td>\n",
              "      <td>-2.054629</td>\n",
              "      <td>-1.207035</td>\n",
              "      <td>2.713798</td>\n",
              "      <td>-0.921727</td>\n",
              "      <td>0.488899</td>\n",
              "      <td>0.856958</td>\n",
              "      <td>-0.518210</td>\n",
              "      <td>-0.239803</td>\n",
              "      <td>0.053463</td>\n",
              "      <td>0.208193</td>\n",
              "      <td>-0.446291</td>\n",
              "      <td>True</td>\n",
              "      <td>0.667535</td>\n",
              "      <td>0.747441</td>\n",
              "      <td>-0.574679</td>\n",
              "      <td>-0.110386</td>\n",
              "      <td>0.131748</td>\n",
              "      <td>-0.018087</td>\n",
              "      <td>-0.440363</td>\n",
              "      <td>True</td>\n",
              "      <td>0.005928</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>318</td>\n",
              "      <td>5130.0</td>\n",
              "      <td>-20.239846</td>\n",
              "      <td>19.914573</td>\n",
              "      <td>-5.128942</td>\n",
              "      <td>22.540444</td>\n",
              "      <td>-9.099782</td>\n",
              "      <td>5.446464</td>\n",
              "      <td>-0.336779</td>\n",
              "      <td>-0.241715</td>\n",
              "      <td>1.080021</td>\n",
              "      <td>0.297595</td>\n",
              "      <td>-0.320653</td>\n",
              "      <td>0.776832</td>\n",
              "      <td>12.177610</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.395035</td>\n",
              "      <td>-0.175066</td>\n",
              "      <td>1.042218</td>\n",
              "      <td>0.398132</td>\n",
              "      <td>-0.352921</td>\n",
              "      <td>0.768642</td>\n",
              "      <td>12.146941</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.030669</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>324</td>\n",
              "      <td>5210.0</td>\n",
              "      <td>14.052632</td>\n",
              "      <td>-2.894737</td>\n",
              "      <td>-14.035088</td>\n",
              "      <td>-6.210526</td>\n",
              "      <td>-35.666667</td>\n",
              "      <td>26.824561</td>\n",
              "      <td>0.297949</td>\n",
              "      <td>-0.065949</td>\n",
              "      <td>-0.657033</td>\n",
              "      <td>0.111894</td>\n",
              "      <td>-1.011791</td>\n",
              "      <td>1.498453</td>\n",
              "      <td>-18.103348</td>\n",
              "      <td>True</td>\n",
              "      <td>3.470738</td>\n",
              "      <td>-0.777636</td>\n",
              "      <td>-3.780886</td>\n",
              "      <td>-1.955058</td>\n",
              "      <td>-9.156151</td>\n",
              "      <td>8.037463</td>\n",
              "      <td>-13.768295</td>\n",
              "      <td>True</td>\n",
              "      <td>4.335053</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>337</td>\n",
              "      <td>5360.0</td>\n",
              "      <td>-20.126063</td>\n",
              "      <td>27.767063</td>\n",
              "      <td>24.634831</td>\n",
              "      <td>8.226913</td>\n",
              "      <td>37.055623</td>\n",
              "      <td>-44.281419</td>\n",
              "      <td>0.600517</td>\n",
              "      <td>0.004345</td>\n",
              "      <td>0.063775</td>\n",
              "      <td>-0.354853</td>\n",
              "      <td>0.369243</td>\n",
              "      <td>0.081847</td>\n",
              "      <td>32.512074</td>\n",
              "      <td>True</td>\n",
              "      <td>0.548324</td>\n",
              "      <td>0.078570</td>\n",
              "      <td>0.128785</td>\n",
              "      <td>-0.326194</td>\n",
              "      <td>0.469064</td>\n",
              "      <td>-0.042143</td>\n",
              "      <td>32.420542</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.091532</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>389</td>\n",
              "      <td>6150.0</td>\n",
              "      <td>30.346441</td>\n",
              "      <td>-12.025085</td>\n",
              "      <td>-15.692881</td>\n",
              "      <td>14.220339</td>\n",
              "      <td>-48.172881</td>\n",
              "      <td>22.642034</td>\n",
              "      <td>0.728696</td>\n",
              "      <td>0.045821</td>\n",
              "      <td>0.433846</td>\n",
              "      <td>-0.595629</td>\n",
              "      <td>0.221493</td>\n",
              "      <td>0.467086</td>\n",
              "      <td>-9.983346</td>\n",
              "      <td>True</td>\n",
              "      <td>0.734787</td>\n",
              "      <td>0.045961</td>\n",
              "      <td>0.430759</td>\n",
              "      <td>-0.595959</td>\n",
              "      <td>0.218982</td>\n",
              "      <td>0.465033</td>\n",
              "      <td>-9.981596</td>\n",
              "      <td>True</td>\n",
              "      <td>0.001750</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0    seed  ...  qpt-mpc-error  qpt-mpc-er_flag\n",
              "190         190  3150.0  ...       0.275020             True\n",
              "285         285  4590.0  ...       0.005928             True\n",
              "318         318  5130.0  ...      -0.030669             True\n",
              "324         324  5210.0  ...       4.335053             True\n",
              "337         337  5360.0  ...      -0.091532             True\n",
              "389         389  6150.0  ...       0.001750             True\n",
              "\n",
              "[6 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTOCWn7KftS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}