{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newton_method.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4K+jFSN7OLCau4RnXxRLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annechris13/Master-Thesis/blob/master/newton_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW72Blyw1922",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBiXLGmPd2K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHE7paKteMaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "df=pd.read_csv('gdrive/My Drive/test_cases.csv')\n",
        "# df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lpy6-HQ2ErN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ip=0\n",
        "# #example problem - 2 batches , 2 variable qp\n",
        "# nbatch=2\n",
        "# nBatch=nbatch\n",
        "# nx=2\n",
        "# nineq=2\n",
        "# neq=1\n",
        "# #to do: extract dimensions from problem parameters + check/add batch dimension\n",
        "# Q=torch.tensor([[4,1,1,2],[6,2,2,2]]).view(nbatch,nx,nx).type(torch.DoubleTensor)\n",
        "# p=torch.tensor([[1,1],[1,6]]).view(nbatch,nx).type(torch.DoubleTensor)\n",
        "# G=torch.tensor([[-1,0,0,-1],[-1,0,0,-1]]).view(nbatch,nineq,nx).type(torch.DoubleTensor)\n",
        "# h=torch.tensor([[0,0],[0,0]]).view(nbatch,nineq).type(torch.DoubleTensor)\n",
        "# A=torch.tensor([[1,1],[2,3]]).view(nbatch,neq,nx).type(torch.DoubleTensor)\n",
        "# b=torch.tensor([[1],[4]]).view(nbatch,neq).type(torch.DoubleTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk8sm1r0dWD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ip=\"csv\"\n",
        "nbatch=len(df)\n",
        "nx=6\n",
        "nineq=6\n",
        "neq=3\n",
        "Q=[]\n",
        "p=[]\n",
        "G=[]\n",
        "h=[]\n",
        "A=[]\n",
        "b=[]\n",
        "for i in range(nbatch):\n",
        "  seed=int(df[\"seed\"][i])\n",
        "  random.seed(seed)\n",
        "  Q.append(make_spd_matrix(nx,random_state=seed).reshape(1,-1))\n",
        "  p.append([random.randint(0,9) for i in range(nx)])#.astype(float))\n",
        "  G.append([random.randint(0,9)*((-1)**random.randint(0,1)) for i in range(nineq*nx)])#.astype(float))\n",
        "  h.append([0 for i in range(nineq)])#.astype(float))\n",
        "  A.append([random.randint(0,9) for i in range(neq*nx)])#.astype(float))\n",
        "  b.append([random.randint(0,9) for i in range(neq)])#.astype(float)  )\n",
        "\n",
        "Q=torch.tensor(Q).view(nbatch,nx,nx).type(torch.DoubleTensor)\n",
        "p=torch.tensor(p).view(nbatch,nx).type(torch.DoubleTensor)\n",
        "G=torch.tensor(G).view(nbatch,nineq,nx).type(torch.DoubleTensor)\n",
        "h=torch.tensor(h).view(nbatch,nineq).type(torch.DoubleTensor)\n",
        "A=torch.tensor(A).view(nbatch,neq,nx).type(torch.DoubleTensor)\n",
        "b=torch.tensor(b).view(nbatch,neq).type(torch.DoubleTensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OBoEaK52Szk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if Q is psd:\n",
        "for i in range(nbatch):\n",
        "  e,_=torch.eig(Q[i])\n",
        "  if not torch.all(e[:,0]>0):\n",
        "    raise RuntimeError(\"Q is not PD\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb-4GMN2cHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lu_hack(x):\n",
        "    data, pivots = x.lu(pivot=not x.is_cuda)\n",
        "    if x.is_cuda:\n",
        "        if x.ndimension() == 2:\n",
        "            pivots = torch.arange(1, 1+x.size(0)).int().cuda()\n",
        "        elif x.ndimension() == 3:\n",
        "            pivots = torch.arange(\n",
        "                1, 1+x.size(1),\n",
        "            ).unsqueeze(0).repeat(x.size(0), 1).int().cuda()\n",
        "        else:\n",
        "            assert False\n",
        "    return (data, pivots)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFQ6FkJ62yFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bdiag(d):\n",
        "    nBatch, sz, _ = d.size()\n",
        "    D = torch.zeros(nBatch, sz, sz).type_as(d)\n",
        "    I = torch.eye(sz).repeat(nBatch, 1, 1).type_as(d).bool()\n",
        "    D[I] = d.squeeze().view(-1)\n",
        "    return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNYAn_fc23kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Hessian(Q,G,A):\n",
        "    nbatch,nineq,nx=G.size()\n",
        "    neq=A.size()[1]\n",
        "    B1=torch.zeros(nbatch,nx+nineq,nx+nineq).type_as(Q)\n",
        "    B3=torch.zeros(nbatch,neq+nineq,nx+nineq).type_as(Q)\n",
        "    B4=torch.zeros(nbatch,neq+nineq,neq+nineq).type_as(Q)\n",
        "\n",
        "    B1[:,:nx,:nx]=Q\n",
        "    B1[:,-nineq:,-nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B3[:,:nineq,:nx]=G\n",
        "    B3[:,-neq:,:nx]=A\n",
        "    B3[:,:nineq,nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B2=torch.transpose(B3, dim0=2, dim1=1)\n",
        "\n",
        "    H=torch.cat((torch.cat((B1,B2),dim=2),torch.cat((B3,B4),dim=2)),dim=1)\n",
        "  \n",
        "    return H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnl836f27g8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def solve_kkt(H,rx,rs,rz,ry,d=None):\n",
        "    if d!=None:\n",
        "      D=bdiag(d)\n",
        "      H[:,nx:nx+nineq,nx:nx+nineq]=D\n",
        "    # print(\"H: \",H)\n",
        "    F=torch.cat((rx,rs,rz,ry), dim=1)\n",
        "    H_lu,H_piv= lu_hack(H)\n",
        "    step=F.lu_solve(H_lu,H_piv)\n",
        "\n",
        "    rx=step[:,:nx,:]\n",
        "    rs=step[:,nx:nx+nineq,:]\n",
        "    rz=step[:,nx+nineq:-neq,:]\n",
        "    ry=step[:,-neq:,:]\n",
        "    return(rx,rs,rz,ry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGgtol371pyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_initial(z):\n",
        "      nbatch,_,_=z.size()\n",
        "      dz=torch.ones(z.size()).type_as(z)\n",
        "      alpha=torch.tensor([]).type_as(z)\n",
        "      for b in range(nbatch):\n",
        "        step=torch.tensor([-0.1]).type_as(z)\n",
        "        z_=z[b,:,:]\n",
        "        dz_=dz[b,:,:]\n",
        "        while True:\n",
        "          if (z_+step*dz_ >0).all():\n",
        "            if step<0:\n",
        "              alpha=torch.cat((alpha,torch.tensor([0]).type_as(z)))\n",
        "            else:\n",
        "              alpha=torch.cat((alpha,1+step))\n",
        "            break\n",
        "          else:\n",
        "            step=step+0.1\n",
        "      return alpha.view(nbatch,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0e1u9MNug7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_step(v,dv):\n",
        "      #TO DO: find efficient and accurate line search algorithm\n",
        "      nbatch,_,_=v.size()\n",
        "      alpha=torch.tensor([]).type_as(v)\n",
        "      for b in range(nbatch):\n",
        "        step=torch.tensor([1]).type_as(v)\n",
        "        v_=v[b,:,:]\n",
        "        dv_=dv[b,:,:]\n",
        "        while True:\n",
        "          if (v_+step*dv_ >=0).all() or step==0:\n",
        "            alpha=torch.cat((alpha,step))\n",
        "            break\n",
        "          else:\n",
        "            step=step-0.1\n",
        "      return alpha.view(nbatch,1,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MqWmBrLrgYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pure_newton(Q,G,A,p,b,h,x,s,z,y, max_iter=20):\n",
        "    H=get_Hessian(Q,G,A)\n",
        "    A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "    G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "    count=0\n",
        "    for i in range(max_iter):\n",
        "        rx= -(torch.bmm(A_T,y)+torch.bmm(G_T,z)+torch.bmm(Q,x)+p.unsqueeze(2))\n",
        "        rs=-z\n",
        "        rz=-(torch.bmm(G,x)+s-h.unsqueeze(2))\n",
        "        ry=-(torch.bmm(A,x)-b.unsqueeze(2))\n",
        "        d=z/s\n",
        "        #affine step calculation\n",
        "        dx,ds,dz,dy=solve_kkt(H,rx,rs,rz,ry,d)\n",
        "        #step size calculation\n",
        "        alpha = torch.min(get_step(z, dz),get_step(s, ds))\n",
        "        #update step\n",
        "        x+=alpha*dx\n",
        "        s+=alpha*ds\n",
        "        z+=alpha*dz\n",
        "        y+=alpha*dy\n",
        "        mu=torch.abs(torch.bmm(torch.transpose(s,dim0=2,dim1=1),z).sum(1))\n",
        "        pri_resid=torch.abs(rx)\n",
        "        dual_1_resid=torch.abs(rz)\n",
        "        dual_2_resid=torch.abs(ry)\n",
        "        resids=np.array([pri_resid.max(),mu.max(),dual_1_resid.max(),dual_2_resid.max()])\n",
        "        if (resids<1e-12).all():\n",
        "          print(\"Early exit at iteration no:\",i)\n",
        "          return(x,s,z,y)\n",
        "        if(i==max_iter-1 and (resids>1e-10).any()):\n",
        "          print(\"no of mu not converged: \",len(mu[mu>1e-10]))\n",
        "          print(\"no of primal residual not converged: \",len(pri_resid[pri_resid>1e-10]))\n",
        "          print(\"no of dual residual 1 not converged: \",len(dual_1_resid[dual_1_resid>1e-10]))\n",
        "          print(\"no of dual residual 2 not converged: \",len(dual_2_resid[dual_2_resid>1e-10]))\n",
        "          raise RuntimeWarning(\"Residuals not converged, need more itrations\")\n",
        "\n",
        "    return(x,s,z,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA7V4dfF5BDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H=get_Hessian(Q,G,A)\n",
        "A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "#initial solution\n",
        "x,s,z,y=solve_kkt(H,-p.unsqueeze(2),torch.zeros(nbatch,nineq).unsqueeze(2).type_as(Q),h.unsqueeze(2),b.unsqueeze(2))\n",
        "alpha_p=get_initial(-z)\n",
        "alpha_d=get_initial(z)\n",
        "s=-z+alpha_p*(torch.ones(z.size()).type_as(z))\n",
        "z=z+alpha_d*(torch.ones(z.size()).type_as(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S63UdqzF6cTL",
        "colab_type": "code",
        "outputId": "c0a9510c-1688-4bbc-e423-eba9daf88ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "x,s,z,y=pure_newton(Q,G,A,p,b,h,x,s,z,y,25)\n",
        "op_val=0.5*torch.bmm(torch.transpose(x,dim0=2,dim1=1),torch.bmm(Q,x))+torch.bmm(torch.transpose(p.unsqueeze(2),dim0=2,dim1=1),x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of mu not converged:  81\n",
            "no of primal residual not converged:  459\n",
            "no of dual residual 1 not converged:  438\n",
            "no of dual residual 2 not converged:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeWarning",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-684fc1f9928f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpure_newton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mop_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-9ce94d3adeac>\u001b[0m in \u001b[0;36mpure_newton\u001b[0;34m(Q, G, A, p, b, h, x, s, z, y, max_iter)\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no of dual residual 1 not converged: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdual_1_resid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdual_1_resid\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no of dual residual 2 not converged: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdual_2_resid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdual_2_resid\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Residuals not converged, need more itrations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeWarning\u001b[0m: Residuals not converged, need more itrations"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYAO8ThCy5YF",
        "colab_type": "code",
        "outputId": "de72ccc7-b0ad-41fe-af0e-dbd5719368d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "if ip!=\"csv\":\n",
        "    print(\"optimal point: \\n\", x.numpy().reshape(nbatch,-1))\n",
        "    print(\"\\noptimal objective value: \\n\", op_val.numpy().reshape(nbatch,-1))\n",
        "\n",
        "if ip==\"csv\":\n",
        "    cols=[str(i)+\"nwt\" for i in range(nx)]\n",
        "    error_cp=np.zeros(nbatch)\n",
        "    error_qp=np.zeros(nbatch)\n",
        "    new=pd.DataFrame(x.numpy().round(6).reshape(nbatch,-1),columns=cols)\n",
        "    tmp=df.copy()\n",
        "    for i,col in enumerate(cols):\n",
        "      tmp[col]=new[col].copy()\n",
        "      error_cp+=np.round(tmp[str(i)+\"cp\"],6)-np.round(tmp[col],6)\n",
        "      error_qp+=np.round(tmp[str(i)+\"qpt\"],6)-np.round(tmp[col],6)\n",
        "\n",
        "    tmp[\"cp-nwt-error\"]=error_cp\n",
        "    tmp[\"cp-nwt-er_flag\"]=error_cp!=0\n",
        "    tmp[\"qpt-nwt-error\"]=error_qp\n",
        "    tmp[\"qpt-nwt-er_flag\"]=error_qp!=0\n",
        "    print(\"No.of problems solved: \",len(tmp))\n",
        "    print(\"No.of errors from Newton Method: \",len(error_cp[error_cp!=0]),\" (\",round(len(error_cp[error_cp!=0])*100/len(tmp),2),\")\")\n",
        "    print(\"No.of errors from qpth: \",len(tmp[tmp[\"cp-qpt-er_flag\"]]),\" (\",round(len(tmp[tmp[\"cp-qpt-er_flag\"]])*100/len(tmp),2),\")\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of problems solved:  639\n",
            "No.of errors from Newton Method:  80  ( 12.52 )\n",
            "No.of errors from qpth:  22  ( 3.44 )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmbRf-ZF3tTd",
        "colab_type": "text"
      },
      "source": [
        "The newton method produces large no.of inaccurate results (6.4%)(when using a step size decrement of 0.01 (instead of 0.1) in the get_step(), the inaacuracy reduces to just 41 problems(6.42%). This can be associated to the RuntimeWarning that the residuals (and the duality gap mu) has not converged to a value that is close to zero. As long as these values doesnt converge to zero, the results are not optimal! This departure from convergence might be a result of the small steps the algorithm is restricted to take in case of the pure Newton method.\n",
        "\n",
        "Work around: Add centering component to bias the iterates to move along the central path - path following algorithms - which would help in significant decrease in residuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsvQdtUJ3e90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}