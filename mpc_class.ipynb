{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mpc_class.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPibQ4rTan1PJUWCsd0EFXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annechris13/Master-Thesis/blob/master/mpc_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nu3TmRPBX1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('error')\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9m160zXBgwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_Q_pd(Q):\n",
        "  #check if Q is pd:\n",
        "  nbatch=Q.size()[0]\n",
        "  for i in range(nbatch):\n",
        "    e,_=torch.eig(Q[i])\n",
        "    if not torch.all(e[:,0]>0):\n",
        "      raise RuntimeError(\"Q is not PD\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0KWqfKaBr5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lu_hack(x):\n",
        "    #do lu factorization of x\n",
        "    data, pivots = x.lu(pivot=not x.is_cuda)\n",
        "    if x.is_cuda:\n",
        "        if x.ndimension() == 2:\n",
        "            pivots = torch.arange(1, 1+x.size(0)).int().cuda()\n",
        "        elif x.ndimension() == 3:\n",
        "            pivots = torch.arange(\n",
        "                1, 1+x.size(1),\n",
        "            ).unsqueeze(0).repeat(x.size(0), 1).int().cuda()\n",
        "        else:\n",
        "            assert False\n",
        "    return (data, pivots)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozyl6TS-Bt1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bdiag(d):\n",
        "    #return diagonal matrix with diagonal entries d\n",
        "    nBatch, sz, _ = d.size()\n",
        "    D = torch.zeros(nBatch, sz, sz).type_as(d)\n",
        "    I = torch.eye(sz).repeat(nBatch, 1, 1).type_as(d).bool()\n",
        "    D[I] = d.squeeze().view(-1)\n",
        "    return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Co4ppqBv4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Hessian(Q,G,A):\n",
        "    #get the hessian kkt matrix\n",
        "    nbatch,nineq,nx=G.size()\n",
        "    neq=A.size()[1]\n",
        "    B1=torch.zeros(nbatch,nx+nineq,nx+nineq).type_as(Q)\n",
        "    B3=torch.zeros(nbatch,neq+nineq,nx+nineq).type_as(Q)\n",
        "    B4=torch.zeros(nbatch,neq+nineq,neq+nineq).type_as(Q)\n",
        "\n",
        "    B1[:,:nx,:nx]=Q\n",
        "    #D here is unit identity matrix\n",
        "    B1[:,-nineq:,-nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B3[:,:nineq,:nx]=G\n",
        "    B3[:,-neq:,:nx]=A\n",
        "    B3[:,:nineq,nineq:]=torch.eye(nineq).repeat(nbatch,1,1).type_as(Q)\n",
        "\n",
        "    B2=torch.transpose(B3, dim0=2, dim1=1)\n",
        "\n",
        "    H=torch.cat((torch.cat((B1,B2),dim=2),torch.cat((B3,B4),dim=2)),dim=1)\n",
        "  \n",
        "    return H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Oje_ht_CDMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def solve_kkt(H,rx,rs,rz,ry,d=None):\n",
        "    # solve the KKT system with hessian H and F specified by rx,rs,rz,ry\n",
        "    # the hessian H is modified when d is specified\n",
        "    nx=rx.size()[1]\n",
        "    nineq=rz.size()[1]\n",
        "    neq=ry.size()[1]\n",
        "    if d!=None:\n",
        "      D=bdiag(d)\n",
        "      H[:,nx:nx+nineq,nx:nx+nineq]=D\n",
        "    # print(\"H: \",H)\n",
        "    H_lu,H_piv= lu_hack(H)\n",
        "    F=torch.cat((rx,rs,rz,ry), dim=1)\n",
        "    step=F.lu_solve(H_lu,H_piv)\n",
        "\n",
        "    rx=step[:,:nx,:]\n",
        "    rs=step[:,nx:nx+nineq,:]\n",
        "    rz=step[:,nx+nineq:-neq,:]\n",
        "    ry=step[:,-neq:,:]\n",
        "    return(rx,rs,rz,ry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjlTyY0_CcSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_initial(z):\n",
        "      #get step size using line search for initialization \n",
        "      nbatch,_,_=z.size()\n",
        "      dz=torch.ones(z.size()).type_as(z)\n",
        "      alpha=torch.tensor([]).type_as(z)\n",
        "      for b in range(nbatch):\n",
        "        step=torch.tensor([-0.1]).type_as(z)\n",
        "        z_=z[b,:,:]\n",
        "        dz_=dz[b,:,:]\n",
        "        while True:\n",
        "          if (z_+step*dz_ >0).all():\n",
        "            if step<0:\n",
        "              alpha=torch.cat((alpha,torch.tensor([0]).type_as(z)))\n",
        "            else:\n",
        "              alpha=torch.cat((alpha,1+step))\n",
        "            break\n",
        "          else:\n",
        "            step=step+0.1\n",
        "      return alpha.view(nbatch,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-wD9wg8Cnug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_step(v,dv):\n",
        "#       #get step sizes for each iteration\n",
        "#       #TO DO: find efficient and accurate line search algorithm\n",
        "#       nbatch,_,_=v.size()\n",
        "#       alpha=torch.tensor([]).type_as(v)\n",
        "#       for b in range(nbatch):\n",
        "#         step=torch.tensor([1]).type_as(v)\n",
        "#         v_=v[b,:,:]\n",
        "#         dv_=dv[b,:,:]\n",
        "#         while step>0:\n",
        "#           if (v_+step*dv_ >=0).all() or step==0:\n",
        "#             alpha=torch.cat((alpha,step))\n",
        "#             break\n",
        "#           else:\n",
        "#             step=step-0.01\n",
        "#         if(step<0):\n",
        "#           alpha=torch.cat((alpha,torch.tensor([0]).type_as(v)))\n",
        "#       return alpha.view(nbatch,1,1)\n",
        "\n",
        "# def get_step(v, dv):\n",
        "#     #qpth version of get_step\n",
        "#     a = -v / dv\n",
        "#     a[dv > 0] = max(1.0, a.max())\n",
        "#     return a.min(1)[0].squeeze()\n",
        "\n",
        "def get_step(v,dv):\n",
        "  v=v.squeeze(2)\n",
        "  dv=dv.squeeze(2)\n",
        "  div= -v/dv\n",
        "  ones=torch.ones_like(div)\n",
        "  div=torch.where(torch.isinf(div),ones,div)\n",
        "  div=torch.where(torch.isnan(div),ones,div)\n",
        "  div[dv>0]=max(1.0,div.max())\n",
        "  return (div.min(1)[0]).view(v.size()[0],1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsRlMRzHEjZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mpc(Q,G,A,p,b,h,x,s,z,y, max_iter=20):\n",
        "    nbatch,nx,_=Q.size()\n",
        "    nineq=G.size()[1]\n",
        "    neq=A.size()[1]\n",
        "    H=get_Hessian(Q,G,A)\n",
        "    A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "    G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "    count=0\n",
        "    bat=np.array([i for i in range(nbatch)])\n",
        "    for i in range(max_iter):\n",
        "        # print(\"iteration: \",i)\n",
        "        rx= -(torch.bmm(A_T,y)+torch.bmm(G_T,z)+torch.bmm(Q,x)+p.unsqueeze(2))\n",
        "        rs=-z\n",
        "        rz=-(torch.bmm(G,x)+s-h.unsqueeze(2))\n",
        "        ry=-(torch.bmm(A,x)-b.unsqueeze(2))\n",
        "        d=z/s\n",
        "        mu=torch.abs(torch.bmm(torch.transpose(s,dim0=2,dim1=1),z).sum(1))\n",
        "        pri_resid=torch.abs(rx)\n",
        "        dual_1_resid=torch.abs(rz)\n",
        "        dual_2_resid=torch.abs(ry)\n",
        "        if (i%4==0):\n",
        "          log=((pri_resid.sum(1)<1e-12)*(dual_1_resid.sum(1)<1e-12)*(dual_2_resid.sum(1)<1e-12)*(mu<1e-12)).squeeze(1).numpy().astype(bool)\n",
        "          # print(\"already converged: \",bat[log] )\n",
        "\n",
        "        resids=np.array([pri_resid.max(),mu.max(),dual_1_resid.max(),dual_2_resid.max()])\n",
        "        try:\n",
        "          if (resids<1e-12).all():\n",
        "            # print(\"Early exit at iteration no:\",i)\n",
        "            return(x,s,z,y)\n",
        "        except:\n",
        "          print(bat[torch.isnan(pri_resid.sum(1)).squeeze(1)])\n",
        "          raise RuntimeError(\"invalid res\")\n",
        "        \n",
        "        #affine step calculation\n",
        "        dx_aff,ds_aff,dz_aff,dy_aff=solve_kkt(H,rx,rs,rz,ry,d)\n",
        "        #affine step size calculation\n",
        "        alpha = torch.min(get_step(z, dz_aff),get_step(s, ds_aff))\n",
        "        \n",
        "        #affine updates for s and z\n",
        "        s_aff=s+alpha*ds_aff\n",
        "        z_aff=z+alpha*dz_aff\n",
        "        mu_aff=torch.abs(torch.bmm(torch.transpose(s_aff,dim0=2,dim1=1),z_aff).sum(1))\n",
        "        \n",
        "        #find sigma for centering in the direction of mu\n",
        "        sigma=(mu_aff/mu)**3\n",
        "\n",
        "        #find centering+correction steps\n",
        "        rx=torch.zeros(rx.size()).type_as(Q)\n",
        "        rs=((sigma*mu).unsqueeze(2).repeat(1,nineq,1)-ds_aff*dz_aff)/s\n",
        "        rz=torch.zeros(rz.size()).type_as(Q)\n",
        "        ry=torch.zeros(ry.size()).type_as(Q)\n",
        "        dx_cor,ds_cor,dz_cor,dy_cor=solve_kkt(H,rx,rs,rz,ry,d)\n",
        "\n",
        "        dx=dx_aff+dx_cor\n",
        "        ds=ds_aff+ds_cor\n",
        "        dz=dz_aff+dz_cor\n",
        "        dy=dy_aff+dy_cor\n",
        "        # find update step size\n",
        "        alpha = torch.min(torch.ones(nbatch).type_as(Q).view(nbatch,1,1),0.99*torch.min(get_step(z, dz),get_step(s, ds)))\n",
        "        # update\n",
        "        x+=alpha*dx\n",
        "        s+=alpha*ds\n",
        "        z+=alpha*dz\n",
        "        y+=alpha*dy\n",
        "\n",
        "        if(i==max_iter-1 and (resids>1e-10).any()):\n",
        "          # print(\"no of mu not converged: \",len(mu[mu>1e-10]))\n",
        "          # print(\"no of primal residual not converged: \",len(pri_resid[pri_resid>1e-10]))\n",
        "          # print(\"no of dual residual 1 not converged: \",len(dual_1_resid[dual_1_resid>1e-10]))\n",
        "          # print(\"no of dual residual 2 not converged: \",len(dual_2_resid[dual_2_resid>1e-10]))\n",
        "          print(\"mpc warning: Residuals not converged, need more itrations\")\n",
        "\n",
        "    return(x,s,z,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozDfSFHPEkSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def opt(Q,p,G,h,A,b):\n",
        "  nbatch,nx,_=Q.size()\n",
        "  nineq=G.size()[1]\n",
        "  neq=A.size()[1]\n",
        "  check_Q_pd(Q)\n",
        "  H=get_Hessian(Q,G,A)\n",
        "  A_T=torch.transpose(A,dim0=2,dim1=1)\n",
        "  G_T=torch.transpose(G,dim0=2,dim1=1)\n",
        "  #initial solution\n",
        "  x,s,z,y=solve_kkt(H,-p.unsqueeze(2),torch.zeros(nbatch,nineq).unsqueeze(2).type_as(Q),h.unsqueeze(2),b.unsqueeze(2))\n",
        "  alpha_p=get_initial(-z)\n",
        "  alpha_d=get_initial(z)\n",
        "  s=-z+alpha_p*(torch.ones(z.size()).type_as(z))\n",
        "  z=z+alpha_d*(torch.ones(z.size()).type_as(z))\n",
        "  #main iterations\n",
        "  start = time.time()\n",
        "  x,s,z,y=mpc(Q,G,A,p,b,h,x,s,z,y,30)\n",
        "  op_val=0.5*torch.bmm(torch.transpose(x,dim0=2,dim1=1),torch.bmm(Q,x))+torch.bmm(torch.transpose(p.unsqueeze(2),dim0=2,dim1=1),x)\n",
        "  t = time.time() - start\n",
        "  # print(t)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZRN4j2aEpDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}